import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI
import traceback

# ğŸ”§ Load local environment variables (apenas quando rodar localmente)
load_dotenv()

# âš™ï¸ Page configuration
st.set_page_config(page_title="Legal AI Agent", page_icon="âš–ï¸")
st.title("âš–ï¸ Legal AI Agent")

# ğŸ”‘ Keys and model (Cloud â†’ st.secrets, Local â†’ .env)
api_key = (
    st.secrets.get("OPENROUTER_API_KEY")
    or os.getenv("OPENROUTER_API_KEY")
)
chosen_model = (
    st.secrets.get("DEFAULT_MODEL")
    or os.getenv("DEFAULT_MODEL", "nvidia/nemotron-3-nano-30b-a3b:free")
)
admin_mode = st.secrets.get("ADMIN_MODE") or os.getenv("ADMIN_MODE", "false")

# ğŸš¨ Validate API key
if not api_key:
    st.error("âŒ No API key found. Please configure OPENROUTER_API_KEY.")
    st.stop()

# ğŸ¤– OpenRouter client
client = OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

# ğŸ§¹ Button to clear conversation
if st.button("ğŸ§¹ Clear conversation"):
    st.session_state.messages = []
    st.rerun()

# ğŸ’¬ Conversation history
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ğŸ“ User input
if prompt := st.chat_input("How can I assist with your legal inquiry?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        try:
            with st.spinner("ğŸ” Consulting the legal agent..."):
                stream = client.chat.completions.create(
                    model=chosen_model,
                    messages=[
                        {
                            "role": "system",
                            "content": (
                                "You are a helpful and experienced legal assistant. "
                                "Provide accurate and concise legal information, but always advise the user "
                                "to consult a qualified lawyer for specific legal advice."
                            ),
                        }
                    ] + st.session_state.messages,
                    stream=True,
                )

                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        full_response += chunk.choices[0].delta.content
                        message_placeholder.markdown(full_response + "â–Œ")

            message_placeholder.markdown(full_response)

        except Exception as e:
            st.error(f"âš ï¸ An error occurred while generating the response: {e}")
            print(traceback.format_exc())
            full_response = (
                "âš ï¸ Sorry, I couldn't process your request at the moment. Please try again later."
            )
            message_placeholder.markdown(full_response)

    st.session_state.messages.append({"role": "assistant", "content": full_response})

    


